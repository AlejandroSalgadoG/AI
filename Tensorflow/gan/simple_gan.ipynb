{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.random import normal\n",
    "from tensorflow import concat, dtypes, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "zeros = x_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Flatten(input_shape=[28, 28]))\n",
    "\n",
    "discriminator.add(Dense(150, activation=\"relu\"))\n",
    "discriminator.add(Dense(100, activation=\"relu\"))\n",
    "\n",
    "discriminator.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_size = 100\n",
    "\n",
    "generator = Sequential()\n",
    "\n",
    "# like decoder part of an autoencoder\n",
    "generator.add(Dense(100, activation=\"relu\", input_shape=[coding_size]))\n",
    "generator.add(Dense(150, activation=\"relu\"))\n",
    "generator.add(Dense(784, activation=\"relu\"))\n",
    "generator.add(Reshape([28, 28]))\n",
    "\n",
    "# generator is not compiled because it is never trained on its own\n",
    "# it is only trained together with the discriminator (full gan model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = Sequential([generator, discriminator])\n",
    "\n",
    "# when full gan is assembled the discriminator should not be trained\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# buffer size is how many slices to load into memory at the same time\n",
    "dataset_obj = Dataset.from_tensor_slices(zeros).shuffle(buffer_size=1000)\n",
    "# prefetch allows later elements to be prepared while the current element is being processed\n",
    "dataset = dataset_obj.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator = gan.layers\n",
    "\n",
    "epochs = 1\n",
    "n_batch = len(zeros) // batch_size\n",
    "\n",
    "def train_discriminator(batch):\n",
    "    discriminator.trainable = True\n",
    "\n",
    "    noise = normal(shape=[batch_size, coding_size])\n",
    "    gen_data = generator(noise)\n",
    "    real_data = dtypes.cast(batch, float32)\n",
    "    input_data = concat([gen_data, real_data], axis=0)\n",
    "    y = np.concatenate([np.zeros(shape=(batch_size,1)), np.ones(shape=(batch_size, 1))])\n",
    "\n",
    "    discriminator.train_on_batch(input_data, y)        \n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    noise = normal(shape=[batch_size, coding_size])\n",
    "    y = np.ones(shape=(batch_size, 1))\n",
    "\n",
    "    gan.train_on_batch(noise, y)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch = {epoch + 1}\")\n",
    "    for i, batch in enumerate(dataset, start=1):\n",
    "        print(f\"batch = {i}/{n_batch}\")\n",
    "        train_discriminator(batch) # phase 1\n",
    "        train_generator() # phase 2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = normal(shape=[1, coding_size])\n",
    "plt.imshow(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generator(noise)\n",
    "plt.imshow(images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
